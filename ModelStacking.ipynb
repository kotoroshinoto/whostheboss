{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from typing import Tuple, List\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from scribe_classifier.data.canada.NOCdb.models.simple_model import SimpleModel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scribe_classifier.data.canada.NOCdb.readers import TitleSet, TitleRecord\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scribe_classifier.data.canada.NOCdb.readers import AllCodes\n",
    "from scribe_classifier.data.canada.NOCdb.models.neural_networks.artificial_neural_net import ANNclassifier\n",
    "# from keras.layers import Dense, Dropout\n",
    "# from keras.models import Sequential, load_model\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from scribe_classifier.data.canada.NOCdb.models.neural_networks.combined_models import CombinedModels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdl_strs = dict()\n",
    "for target_level in range(1,4):\n",
    "    level_mdl_strs = dict()\n",
    "    level_mdl_strs['sgd'] = 'source_data/pickles/canada/trained_models/simple.lvl%d.sgdsv.P' % target_level\n",
    "    level_mdl_strs['bayes'] = 'source_data/pickles/canada/trained_models/simple.lvl%d.bayes.P' % target_level\n",
    "    if target_level != 3:\n",
    "        level_mdl_strs['ann'] = 'nnmodels/ANN/neural_net_level%d.P' % target_level\n",
    "    mdl_strs[target_level]= level_mdl_strs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "mdls = dict()\n",
    "mdl_strs\n",
    "for target_level in range(1,4):\n",
    "    level_mdls = dict()\n",
    "    level_mdls['sgd'] = SimpleModel.load_from_pickle('source_data/pickles/canada/trained_models/simple.lvl%d.sgdsv.P' % target_level, is_path=True)  # type: SimpleModel\n",
    "    level_mdls['bayes'] = SimpleModel.load_from_pickle('source_data/pickles/canada/trained_models/simple.lvl%d.bayes.P' % target_level, is_path=True)  # type: SimpleModel\n",
    "    if target_level != 3:\n",
    "        level_mdls['ann'] = ANNclassifier.load_from_pickle('nnmodels/ANN/neural_net_level%d.P' % target_level)  # type: ANNclassifier\n",
    "    mdls[target_level]= level_mdls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ac = AllCodes.load_from_pickle('source_data/pickles/canada/tidy_sets/all_codes.P', is_path=True)\n",
    "ac.add_emptyset()\n",
    "lbl_bin = LabelBinarizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_level=3\n",
    "lbl_bin.fit(ac.get_codes_for_level(target_level))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    }
   ],
   "source": [
    "cmb_mdls = CombinedModels('source_data/pickles/canada/tidy_sets/all_codes.P',\n",
    "                          mdl_strs[1],\n",
    "                          mdl_strs[2],\n",
    "                          mdl_strs[3],\n",
    "                          target_level=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = TitleSet.load_from_pickle('source_data/pickles/canada/test_sets/train.set.lvl%d.P' % target_level, is_path=True).copy_and_append_empty_string_class()\n",
    "test = TitleSet.load_from_pickle('source_data/pickles/canada/test_sets/test.set.lvl%d.P' % target_level, is_path=True).copy_and_append_empty_string_class()\n",
    "valid = TitleSet.load_from_pickle('source_data/pickles/canada/test_sets/valid.set.lvl%d.P' % target_level, is_path=True).copy_and_append_empty_string_class()\n",
    "\n",
    "level_mdls = mdls[target_level]\n",
    "if 'sgd' in level_mdls:\n",
    "    trained_simple_sgd = mdls[target_level]['sgd']\n",
    "else:\n",
    "    trained_simple_sgd = None\n",
    "if 'bayes' in level_mdls:\n",
    "    trained_simple_bayes = mdls[target_level]['bayes']\n",
    "else:\n",
    "    trained_simple_bayes=None\n",
    "if 'ann' in level_mdls:\n",
    "    trained_nn_clf = mdls[target_level]['ann']\n",
    "else:\n",
    "    trained_nn_clf = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_titles = train.get_title_vec()\n",
    "t_titles = test.get_title_vec()\n",
    "v_titles = valid.get_title_vec()\n",
    "T_labels = train.get_code_vec(target_level=target_level)\n",
    "t_labels = test.get_code_vec(target_level=target_level)\n",
    "v_labels = valid.get_code_vec(target_level=target_level)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_models = 0\n",
    "if trained_simple_sgd is not None:\n",
    "    t_sgd_proba = trained_simple_sgd.predict_proba(t_titles)\n",
    "    num_models += 1\n",
    "else:\n",
    "    t_sgd_proba = np.zeros((len(t_titles),len(ac.get_codes_for_level(target_level))))\n",
    "if trained_simple_bayes is not None:\n",
    "    t_bayes_proba = trained_simple_bayes.predict_proba(t_titles)\n",
    "    num_models += 1\n",
    "else:\n",
    "    t_bayes_proba = np.zeros((len(t_titles),len(ac.get_codes_for_level(target_level))))\n",
    "if trained_nn_clf is not None:\n",
    "    t_nn_proba = trained_nn_clf.predict_proba(t_titles)\n",
    "    num_models += 1\n",
    "else:\n",
    "    t_nn_proba = np.zeros((len(t_titles),len(ac.get_codes_for_level(target_level))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_proba = (t_sgd_proba + t_bayes_proba + t_nn_proba) / num_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_preds = lbl_bin.inverse_transform(avg_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        001       0.94      0.91      0.93        82\n",
      "        011       0.98      0.96      0.97        57\n",
      "        012       0.93      0.93      0.93        59\n",
      "        013       1.00      0.87      0.93        15\n",
      "        021       0.93      0.97      0.95        40\n",
      "        031       0.92      0.92      0.92        26\n",
      "        041       0.98      0.98      0.98        82\n",
      "        042       0.94      0.89      0.91        54\n",
      "        043       0.93      0.72      0.81        18\n",
      "        051       0.95      0.93      0.94        58\n",
      "        060       1.00      0.88      0.93         8\n",
      "        062       0.96      0.86      0.91        28\n",
      "        063       0.71      1.00      0.83        20\n",
      "        065       0.95      0.95      0.95        19\n",
      "        071       0.86      0.91      0.88        33\n",
      "        073       0.93      1.00      0.96        27\n",
      "        081       0.83      1.00      0.91        10\n",
      "        082       0.91      0.91      0.91        35\n",
      "        091       0.97      0.83      0.90        36\n",
      "        111       0.92      0.88      0.90        40\n",
      "        112       0.88      0.89      0.88        56\n",
      "        121       0.93      0.89      0.91        62\n",
      "        122       0.90      0.90      0.90        79\n",
      "        124       0.88      1.00      0.93        14\n",
      "        125       0.80      1.00      0.89        12\n",
      "        131       0.93      0.93      0.93        29\n",
      "        141       0.84      0.72      0.78        29\n",
      "        142       0.87      0.95      0.91        21\n",
      "        143       0.83      0.91      0.87        32\n",
      "        145       0.79      0.62      0.70        24\n",
      "        151       0.87      0.95      0.91        21\n",
      "        152       0.90      0.88      0.89        50\n",
      "        211       1.00      0.75      0.86        44\n",
      "        212       0.91      0.54      0.68        39\n",
      "        213       0.85      0.83      0.84        48\n",
      "        214       0.95      0.88      0.91        41\n",
      "        215       1.00      0.86      0.92        14\n",
      "        216       1.00      0.89      0.94         9\n",
      "        217       0.90      1.00      0.95        43\n",
      "        221       0.90      0.88      0.89        50\n",
      "        222       0.98      0.87      0.92        53\n",
      "        223       0.95      0.83      0.88        46\n",
      "        224       0.90      0.95      0.92        56\n",
      "        225       0.96      0.92      0.94        48\n",
      "        226       0.95      0.85      0.90        62\n",
      "        227       0.91      0.96      0.94        55\n",
      "        228       0.87      0.93      0.90        14\n",
      "        301       0.94      0.91      0.93        34\n",
      "        311       0.93      0.84      0.88        63\n",
      "        312       1.00      0.70      0.82        10\n",
      "        313       1.00      0.77      0.87        13\n",
      "        314       1.00      0.96      0.98        26\n",
      "        321       0.97      0.95      0.96        94\n",
      "        322       0.94      1.00      0.97        15\n",
      "        323       0.94      0.91      0.92        53\n",
      "        341       0.89      0.94      0.91        50\n",
      "        401       0.97      1.00      0.98        28\n",
      "        402       1.00      0.95      0.98        43\n",
      "        403       1.00      0.92      0.96        38\n",
      "        411       1.00      0.92      0.96        24\n",
      "        415       0.84      0.79      0.82        39\n",
      "        416       0.91      0.91      0.91       152\n",
      "        421       0.95      0.89      0.92        66\n",
      "        431       0.96      0.88      0.92        26\n",
      "        441       1.00      0.88      0.94        17\n",
      "        442       1.00      0.88      0.94        17\n",
      "        511       1.00      1.00      1.00        19\n",
      "        512       0.89      0.89      0.89        53\n",
      "        513       0.91      0.73      0.81        55\n",
      "        521       0.95      0.95      0.95        19\n",
      "        522       0.88      0.87      0.87        76\n",
      "        523       0.90      0.50      0.64        18\n",
      "        524       0.93      0.74      0.83        77\n",
      "        525       0.97      0.88      0.92        76\n",
      "        621       1.00      0.89      0.94         9\n",
      "        622       0.90      0.81      0.85        32\n",
      "        623       1.00      0.82      0.90        17\n",
      "        631       0.88      0.82      0.85        34\n",
      "        632       1.00      1.00      1.00        15\n",
      "        633       0.92      0.92      0.92        12\n",
      "        634       0.95      0.63      0.76        30\n",
      "        641       0.92      0.92      0.92        38\n",
      "        642       0.94      0.98      0.96        50\n",
      "        651       0.92      0.85      0.88        13\n",
      "        652       0.97      0.93      0.95        41\n",
      "        653       1.00      0.95      0.98        21\n",
      "        654       0.88      0.82      0.85        17\n",
      "        655       0.94      0.94      0.94        17\n",
      "        656       0.92      0.75      0.83        32\n",
      "        661       1.00      1.00      1.00         7\n",
      "        662       0.91      0.62      0.74        16\n",
      "        671       0.73      0.69      0.71        16\n",
      "        672       0.85      0.91      0.88        43\n",
      "        673       0.85      0.72      0.78        32\n",
      "        674       0.91      0.91      0.91        35\n",
      "        720       0.92      0.99      0.96       118\n",
      "        723       0.98      0.93      0.95        98\n",
      "        724       1.00      0.95      0.97        75\n",
      "        725       1.00      0.88      0.93        16\n",
      "        727       0.95      0.95      0.95        21\n",
      "        728       0.92      0.94      0.93        36\n",
      "        729       0.87      0.79      0.83        33\n",
      "        730       0.96      0.95      0.95       140\n",
      "        731       0.96      0.92      0.94       130\n",
      "        732       0.94      1.00      0.97        30\n",
      "        733       0.93      0.98      0.95        42\n",
      "        736       0.88      0.88      0.88         8\n",
      "        737       0.94      0.94      0.94        18\n",
      "        738       0.90      0.90      0.90        41\n",
      "        744       0.86      0.87      0.87        85\n",
      "        745       0.91      0.74      0.82        39\n",
      "        751       0.97      0.97      0.97        36\n",
      "        752       0.76      0.78      0.77        32\n",
      "        753       0.95      0.89      0.92        62\n",
      "        761       0.85      0.87      0.86       100\n",
      "        762       0.57      0.80      0.67        15\n",
      "        821       1.00      0.88      0.93         8\n",
      "        822       0.95      0.95      0.95        22\n",
      "        823       0.84      0.84      0.84        25\n",
      "        824       1.00      0.86      0.92        14\n",
      "        825       0.87      0.87      0.87        38\n",
      "        826       0.92      1.00      0.96        12\n",
      "        841       0.85      0.79      0.82        29\n",
      "        842       0.88      0.93      0.90        15\n",
      "        843       0.89      0.86      0.87        36\n",
      "        844       1.00      0.71      0.83         7\n",
      "        861       0.89      0.80      0.84        50\n",
      "        921       0.96      0.93      0.94       171\n",
      "        922       0.98      0.98      0.98        83\n",
      "        923       0.87      0.79      0.83        52\n",
      "        924       0.76      0.94      0.84        34\n",
      "        941       0.94      0.93      0.93       365\n",
      "        942       0.95      0.91      0.93       137\n",
      "        943       0.92      0.95      0.93       192\n",
      "        944       0.94      0.93      0.93       176\n",
      "        946       0.92      0.93      0.93       149\n",
      "        947       0.99      0.96      0.97        90\n",
      "        952       0.95      0.96      0.95       261\n",
      "        953       0.91      0.91      0.91       337\n",
      "        961       0.90      0.87      0.88       305\n",
      "         NA       0.90      1.00      0.95      1827\n",
      "\n",
      "avg / total       0.92      0.92      0.92      9136\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(t_labels, avg_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.69757132e-04,   4.03430575e-04,   1.28636151e-04, ...,\n",
       "          1.97105072e-02,   1.16477776e-02,   6.44573616e-03],\n",
       "       [  6.41162100e-04,   8.56447034e-04,   2.35132829e-04, ...,\n",
       "          1.81672093e-03,   2.97235674e-03,   2.83007324e-02],\n",
       "       [  2.28395584e-04,   2.39655245e-04,   7.47933227e-05, ...,\n",
       "          1.00664787e-04,   2.07467958e-01,   3.10722244e-04],\n",
       "       ..., \n",
       "       [  5.24177449e-03,   7.83312786e-03,   2.39668367e-03, ...,\n",
       "          3.53964604e-02,   1.83501113e-02,   5.04097521e-01],\n",
       "       [  5.24177449e-03,   7.83312786e-03,   2.39668367e-03, ...,\n",
       "          3.53964604e-02,   1.83501113e-02,   5.04097521e-01],\n",
       "       [  5.24177449e-03,   7.83312786e-03,   2.39668367e-03, ...,\n",
       "          3.53964604e-02,   1.83501113e-02,   5.04097521e-01]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmb_mdls.sum_relevant_probas(avg_proba, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.asarray([[1,2,3,4],[5,6,7,8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([], shape=(2, 0), dtype=int64), array([[1],\n",
       "        [5]]), array([[2],\n",
       "        [6]]), array([[3, 4],\n",
       "        [7, 8]])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_split(arr,(0,1,2),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:insight_env]",
   "language": "python",
   "name": "conda-env-insight_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
